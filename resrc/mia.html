<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Research - Medical Image Analysis</title>
  <link rel="stylesheet" href="static/theme.css" type="text/css" />
  <link rel="stylesheet" href="static/gallery.css" type="text/css" />
  <script src="static/js/modernizr.min.js"></script>
  <script>
    var _hmt = _hmt || [];
    (function () {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?bee6e9034f83599f524d47d96877e93c";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>
</head>
<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">

        <a class="header-logo" href="../index.htm" aria-label="Yue's Group" style="font-size:18px;font-weight:bold;width: 400px;">
          <!-- <img src="../static/img/logos/nlp-logo-small.png" alt="" style="width: 40px;height: 40px;"> -->
          智能媒体与认知研究组 
          <p style="font-size:13px;font-weight:lighter">iMoon: Intelligent Media and Cognition Group</p> 
        </a>
        
      <div class="main-menu">
        <ul>
          <li>
            <a href="../index.htm">主页</a>
          </li>

          <li>
            <a href="../people/index.htm">团队</a>
          </li>

          <li class="active">
            <a href="../resrc/index.htm">研究方向</a>
          </li>

          <li>
            <a href="../pubs/index.htm">论文与出版物</a>
          </li>

          <li>
            <a href="../blog/index.htm">最新资讯</a>
          </li>
          <li>
            <a style="font-weight:bold" href="../../en_tsinghua/resrc/mia.html"><b>English</b></a>
          </li>          
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">


  <div>



    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">

          <br>
          <br>
          <h2>研究方向</h2>
          <br>
          <p class="caption"><span class="caption-text">立体视觉</span></p>
          <ul>
            <li class="toctree-l1"><a class="reference internal" href="cv.html">&#8226 3D数据生成</a></li>
            <li class="toctree-l1"><a class="reference internal" href="cv.html">&#8226 3D数据表示</a></li>
            <li class="toctree-l1"><a class="reference internal" href="cv.html">&#8226 3D对象识别与检索</a></li>
          </ul>

          <p class="caption"><span class="caption-text">复杂网络</span></p>
          <ul>
            <li class="toctree-l1"><a class="reference internal" href="ml.html">&#8226 超图结构学习模型</a></li>
            <li class="toctree-l1"><a class="reference internal" href="ml.html">&#8226 超图神经网络模型</a></li>
			<li class="toctree-l1"><a class="reference internal" href="ml.html">&#8226 网络安全态势感知</a></li>
          </ul>
		  
		  
		  <p class="caption"><span class="caption-text">脑科学</span></p>
          <ul>
            <li class="toctree-l1"><a class="reference internal" href="mia.html">&#8226 图像情感预测与图像情感分布的差异</a></li>
            <li class="toctree-l1"><a class="reference internal" href="mia.html">&#8226 基于多超图神经网路的情感识别</a></li>
            <li class="toctree-l1"><a class="reference internal" href="mia.html">&#8226 基于多模态物理信号的情感识别 </a></li>
            <li class="toctree-l1"><a class="reference internal" href="mia.html">&#8226 脑网络建模与挖掘（高阶脑网络）</a></li>
			<li class="toctree-l1"><a class="reference internal" href="mia.html">&#8226 基于动态超图学习的小儿自闭症诊断</a></li>
          </ul>

          <!-- <p class="caption"><span class="caption-text">工业互联网安全</span></p>
          <ul>
            <li class="toctree-l1"><a class="reference internal" href="iis.html">TIE submission</a></li>
            <li class="toctree-l1"><a class="reference internal" href="iis.html">基于代价敏感学习的分类方法（AAAI）</a></li>
            <li class="toctree-l1"><a class="reference internal" href="iis.html">不平衡数据分类（IJCAI）</a></li>
            <li class="toctree-l1"><a class="reference internal" href="iis.html">SDP</a></li>
          </ul> -->




        </div>
      </div>
    </nav>

    <div class="pytorch-container">

      <section data-toggle="wy-nav-shift" class="pytorch-content-wrap">
        <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
          <div class="pytorch-breadcrumbs-wrapper">

            <div role="navigation" aria-label="breadcrumbs navigation">

              <ul class="pytorch-breadcrumbs">

                <li>
                  <a href="index.htm">
                    研究方向
                  </a> &gt;
                </li>
                <li>脑科学</li>
              </ul>


            </div>
          </div>

          <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          目录
          </div>
        </div>

        <div class="pytorch-content-left">

          <div class="rst-content">

            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
              <article itemprop="articleBody" class="pytorch-article">
                <div class="sphx-glr-example-title section" id="finetuning-torchvision-models">
                  <span id="sphx-glr-beginner-finetuning-torchvision-models-tutorial-py"></span>





                  <h1>脑科学<a class="headerlink" href="#" title="Computer-Vision">¶</a></h1>

                  <div class="section" id="emotion-prediction">
                    <h2>图像情感预测与图像情感分布的差异<a class="headerlink" href="#emotion-prediction" title="Permalink to this headline">¶</a></h2>
                    <img src="emotion-prediction.png" style="width:90%;height: 90%;margin: 6px;">
                    
					<p align="center">单词a和单词b是图像分类对于测试图像的目标结果；饼状图显示了通过情感预测对八种情感的目标分布。</p>
					<p>旨在消除情绪鸿沟的具有识别度的图像特征已经有了显著的进步。基于观众对于图像的情绪能够达成共识，现有的工作主要将主导情感类别或情绪状态的平均值作为图像情感的标签。然而观众所感知的情绪受到个人和情景因素共同影响，往往是主观个性化的。因此我们提出将图像的分类转为离散的概率分布来更好的表征图像所隐含的情感信息。此外，我们的方法优化权重来显式的表达不同特征的重要性。</p>
					<p></p>
                    


                  </div>


                  <div class="section" id="emotion-recognition-multi-hypergraph">
                    <h2>基于多超图神经网路的情感识别<a class="headerlink" href="#emotion-recognition-multi-hypergraph" title="Permalink to this headline">¶</a></h2>
                    <img src="emotion-recognition-multi-hypergraph.png" style="width:90%;height: 90%;margin: 6px;">
                    <p align="center">Valence度量下正例与负例在不同脑区的，gamma频段脑电信号的方差</p>
                    <p>在关键领域的核心人工操作中，人员的情绪状态对于任务的完成有着巨大的影响。为了能够实时对人员的情绪状态进行评估，我们使用了多模态超图神经网络对多模态生理信号进行建模，最终将情绪识别任务转化为图结构的顶点分类问题。在这种结构中，不同模态生理信号之间以及不同样本（测试者，刺激）之间的复杂关联被有效的建模。此外，我们选取了不同频率段的脑电信号对情绪与脑电之间的相关性进行量化计算，已有的生物学的结论也和我们的计算结果一致。</p>
                  </div>



                  <div class="section" id="Emotion-Recognition-Multimodel">
                    <h2>基于多模态物理信号的情感识别<a class="headerlink" href="#Emotion-Recognition-Multimodel" title="Permalink to this headline">¶</a></h2>
                    <img src="Emotion-Recognition-Multimodel.png" style="width:90%;height: 90%;margin: 6px;">
                    <p align="center">传统情绪识别 和 个性化情绪识别</p>
                    <p>传统情绪识别将来自不同测试者的样本在测试集和训练集平等对待，而没有考虑训练集和测试集中来自同一测试者的样本之间是否存在更强的关联，来自不同测试者之间的样本存在哪些个人的生理属性中的差异。在这种情景下，我们将个人的生理和心理特征在超图结构中建模，并且对不同模态的生理信号所揭示的样本间的复杂关联通过中间层融合机制自适应进行融合。从而达到个性化精确情绪感知。</p>
                  </div>



                  <div class="section" id="Network-Model-And-Mining">
                    <h2>脑网络建模与挖掘（高阶脑网络）<a class="headerlink" href="#Network-Model-And-Mining" title="Permalink to this headline">¶</a></h2>
                    <p></p>
                    <p>由静息态功能核磁共振成像技术估测得到的脑功能连接网络已经成为神经退化疾病精确诊断中一种比较具有前景的方法。然而传统的功能连接网络仅仅考虑了大脑区域之间的相关性，因此其本质是一个低阶网络。由这类脑网络得到的特征可能无法作为有效的疾病生物标记。针对这个问题，我们提出一种新的高阶功能连接相关性提取方法，该方法可以建模不同脑区对之间低阶相关性的相互作用。最后，我们通过实验验证了高阶功能连接网络在疾病诊断上的有效性。</p>
					<img src="Low-Order-Connection-Network.png" style="width:90%;height: 90%;margin: 6px;">
                    <img src="High-Order-Connection-Network.png" style="width:90%;height: 90%;margin: 6px;">
					<img src="Time-Order-Average.png" style="width:90%;height: 90%;margin: 6px;">
					<p align="center"> 时序均值对诊断比较重要的连接</p>
					<img src="Time-Order-Variance.png" style="width:90%;height: 90%;margin: 6px;">
					<p align="center"> 时序方差对诊断比较重要的连接</p>
				  </div>




					<div class="section" id="Autism-Diagnosis-Dynamic-HyperGraph">
                    <h2>基于动态超图学习的小儿自闭症诊断<a class="headerlink" href="#Autism-Diagnosis-Dynamic-HyperGraph" title="Permalink to this headline">¶</a></h2>
                    <p></p>
                    <p>自闭症是一种由于神经系统失调导致的发育障碍，其病征包括不正常的社交能力、沟通能力、兴趣和行为模式。近年来许多研究发现自闭症与脑网络中某些连接的动态特性之间存在一定关联。本工作提出了一种小儿自闭症诊断算法，首先通过Lasso提取脑网络的动态特性，进一步通过动态超图学习实现自闭症诊断。我们在167个被试上进行了实验，5次交叉验证下诊断正确率达到76%，我们进一步提取出了对自闭症诊断比较重要的脑网络连接，这与之前的研究发现相一致。</p>
				  </div>


					<div class="section" id="PAPERlIST" style="margin-top:80px">
						<p style="font-size:30px"><b><strong>论文列表</strong></b></p>
						<table id="paperlist" class="table " role="grid" style="width: 100%;"> 
								<tbody>
						
						<tr  ><td><p style="line-height:20px;margin-bottom:0rem">Junjie Zhu, Yuanbiao Wang, Yifan Feng, Sicheng Zhao, Xibin Zhao, Yue Gao<br><b><strong>Individual-Specific Emotion Recognition from Multimodal Physiological Signals</strong></b><br>ACM MM 2019 投稿中<br>[<a href="#paperlist">paper</a>]</p></td></tr>
						<tr  ><td><p style="line-height:20px;margin-bottom:0rem">Junjie Zhu , Xibin Zhao , Han Hu , Yue Gao<br><b><strong>Emotion Recognition from Physiological Signals Using Multi-Hypergraph Neural Network</strong></b><br>ICME 2019<br>[<a href="#paperlist">paper</a>]</p></td></tr>
						<tr  ><td><p style="line-height:20px;margin-bottom:0rem">Junjie Zhu, Yuxuan Wei, Yifan Feng, Xibin Zhao, Yue Gao<br><b><strong>Emotion Recognition with Multi-hypergraph Neural Networks Combining Multimodal Physiological Signals</strong></b><br>ACM Transactions on Multimedia Computing, Communications, and Applications 投稿中<br>[<a href="#paperlist">paper</a>]</p></td></tr>
						<tr  ><td><p style="line-height:20px;margin-bottom:0rem">Sicheng Zhao, Guiguang Ding, Yue Gao, Xin Zhao, Youbao Tang, Jungong Han, Hongxun Yao, Qingming Huang<br><b><strong>Discrete Probability Distribution Prediction of Image Emotions With Shared Sparse Learning.</strong></b><br>IEEE Transactions on Affective Computing (TAFFC), 2019.<br>[<a href="#paperlist">paper</a>]</p></td></tr>
						<tr  ><td><p style="line-height:20px;margin-bottom:0rem">Sicheng Zhao, Amir Gholaminejad, Guiguang Ding, Yue Gao, Jungong Han, Kurt Keutzer. <br><b><strong>Personalized Emotion Recognition by Personality-aware High-order Learning of Physiological Signals.</strong></b><br>ACM Transactions on Multimedia Computing Communications and Applications (TOMM) 2019<br>[<a href="#paperlist">paper</a>]</p></td></tr>
						<tr  ><td><p style="line-height:20px;margin-bottom:0rem">Sicheng Zhao, Hongxun Yao, Yue Gao, Guiguang Ding, Tat-Seng Chua. <br><b><strong>Predicting Personalized Image Emotion Perceptions in Social Networks. </strong></b><br>IEEE Transactions on Affective Computing (TAFFC) 2018<br>[<a href="#paperlist">paper</a>]</p></td></tr>
						<tr  ><td><p style="line-height:20px;margin-bottom:0rem">Sicheng Zhao, Yue Gao, Guiguang Ding, Tat-Seng Chua. <br><b><strong>Real-Time Multimedia Social Event Detection in Microblog. </strong></b><br>IEEE Transactions on Cybernetics (TCYB) 2018<br>[<a href="#paperlist">paper</a>]</p></td></tr>
						<tr  ><td><p style="line-height:20px;margin-bottom:0rem">Sicheng Zhao, Hongxun Yao, Yue Gao, Rongrong Ji, Guiguang Ding.  <br><b><strong>Continuous Probability Distribution Prediction of Image Emotions via Multi-Task Shared Sparse Regression. </strong></b><br>IEEE Transactions on Multimedia (TMM) 2017<br>[<a href="#paperlist">paper</a>]</p></td></tr>
						<tr  ><td><p style="line-height:20px;margin-bottom:0rem">Sicheng Zhao, Guiguang Ding, Yue Gao, Jungong Han. <br><b><strong>Learning Visual Emotion Distributions via Multi-Modal Features Fusion. </strong></b><br>ACM International Conference on Multimedia 2017<br>[<a href="#paperlist">paper</a>]</p></td></tr>
						<tr  ><td><p style="line-height:20px;margin-bottom:0rem">Zizhao Zhang, Shoujun Xu, Sichao Shen, Lei Wei, Baojuan Li, Yue Gao <br><b><strong>Diagnosis of Childhood Autism using Dynamic Hypergraph Learning</strong></b><br>MICCAI 2019<br>[<a href="#paperlist">paper</a>]</p></td></tr>
						</tbody>
						</table>
					</div>



                </div>


              </article>

            </div>
            <footer>
              <hr />

              <div role="contentinfo">
                <p>
                  &copy; Copyright 2018-2020, Tsinghua University - iMoon.
                </p>
              </div>
            </footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">

              <ul>
                <li><a class="reference internal" href="#">脑科学</a>
                  <ul>
					
					<li><a class="reference internal" href="#emotion-prediction">图像情感预测与图像情感分布的差异</a>
					</li>
					
                    <li><a class="reference internal" href="#emotion-recognition-multi-hypergraph">基于多超图神经网路的情感识别</a>
                    </li>


                    <li><a class="reference internal" href="#Emotion-Recognition-Multimodel">基于多模态物理信号的情感识别</a>
                    </li>

                    <li><a class="reference internal" href="#Network-Model-And-Mining">脑网络建模与挖掘（高阶脑网络）</a>
                    </li>

                    <li><a class="reference internal" href="#Autism-Diagnosis-Dynamic-HyperGraph">基于动态超图学习的小儿自闭症诊断</a>
                    </li>


                  </ul>
                </li>
              </ul>

            </div>
          </div>
        </div>
      </section>
    </div>
  </div>




  <script type="text/javascript" src="static/js/jquery.js"></script>
  <script type="text/javascript" src="static/js/underscore.js"></script>
  <script type="text/javascript" src="static/js/doctools.js"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>



  <script type="text/javascript" src="static/js/popper.min.js"></script>
  <script type="text/javascript" src="static/js/bootstrap.min.js"></script>
  <script type="text/javascript" src="static/js/theme.js"></script>

  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.Navigation.enable(true);
    });
  </script>



  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-sm-3">
          <h4>iMoon: Intelligent Media and Cognition Group</h4>
          School of Software
          <br> Tsinghua, Beijing 100084
          <br>
          <a href="http://www.tsinghua.edu.cn/publish/newthu/newthu_cnt/intothu/intothu-3-3.html">Directions</a>
        </div>
        <div class="col-sm-3">
          <div class="indent30">
            <h4>Copyright</h4>
            All Rights Reserved.
          </div>
        </div>
      </div>
    </div>
  </div>
  <!-- End Footer -->

  <script type="text/javascript" src="static/js/anchor.min.js"></script>

  <script type="text/javascript">
    mobileMenu.bind();
    mobileTOC.bind();
    pytorchAnchors.bind();

    $(window).on("load", function () {
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
    })

    // Add class to links that have code blocks, since we cannot create links in code blocks
    $("article.pytorch-article a span.pre").each(function (e) {
      $(this).closest("a").addClass("has-code");
    });
  </script>
</body>

</html>