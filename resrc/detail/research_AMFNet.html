<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">


    <title>基于注意力的多模态融合网络在场景语义分割上的应用</title>


    <link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet">
    <link href="../../static/carousel.css" rel="stylesheet">
    <link rel="stylesheet" href="../../static/css/vendor/glyphicons/glyphicons.css">
    <link rel="stylesheet" href="../../static/css/vendor/glyphicons/filetypes.css">
    <link rel="stylesheet" href="../../static/css/vendor/glyphicons/social.css">
    <link href="../../../fonts.googleapis.com/css-family=Open+Sans-400,700,600.css" rel='stylesheet' type='text/css'>
    <link href="../../static/trans.css" rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="../../../maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="../../static/css/bootstrap-markdown.min.css" type="text/css">
    <link rel="stylesheet" href="../../static/css/vendor/layerslider/layerslider.css" type="text/css">
    <link rel="stylesheet" href="../../static/css/styles-cleanred.css" id="grove-styles">
    <link rel="stylesheet" href="../../../cdn.datatables.net/1.10.7/css/jquery.dataTables.min.css" type="text/css">
    <link rel="stylesheet" href="../../static/css/nlp.css" id="nlp-styles">
    <script src="../../../ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../static/js/vendor/jquery/jquery-1.9.1.min.js"><\/script>')</script>
    <script src="../../static/js/vendor/layerslider/greensock.js" type="text/javascript"></script>
    <script src="../../static/js/vendor/layerslider/layerslider.transitions.js" type="text/javascript"></script>
    <script src="../../static/js/vendor/layerslider/layerslider.kreaturamedia.jquery.js"
        type="text/javascript"></script>
    <script src="../../static/js/markdown.js" type="text/javascript"></script>
    <script src="../../static/js/to-markdown.js" type="text/javascript"></script>
    <script src="../../static/js/bootstrap-markdown.js" type="text/javascript"></script>
    <script src="../../static/js/grove-slider.js" type="text/javascript"></script>
    <script src="../../../cdn.datatables.net/1.10.7/js/jquery.dataTables.min.js"></script>
    <script
        src="../../../cdn.datatables.net/plug-ins/1.10.7/features/searchHighlight/dataTables.searchHighlight.min.js"></script>
    <script src="../../../bartaz.github.io/sandbox.js/jquery.highlight.js"></script>
    <link href="../../../cdnjs.cloudflare.com/ajax/libs/select2/4.0.3/css/select2.min.css" rel="stylesheet" />
    <script src="../../../cdnjs.cloudflare.com/ajax/libs/select2/4.0.3/js/select2.min.js"></script>
    <link href="static/css/c5e0117592e540848259ae6882d93f52.css" rel="stylesheet" />
    <script src="static/js/d46d827d0f604446b58cc8d38bdbd84e.js"></script>
</head>

<body>
    <header>
        <nav class="navbar navbar-default grove-navbar navbar-fixed-top" id="imoonbignav">
            <div class="container" id="imoonmidnav">
                <div class="navbar-header">
                    <a href="#" class="grove-toggle collapsed" data-toggle="collapse" data-target=".grove-nav">
                        <i class="glyphicons show_lines"></i>
                    </a>
                    <img class="navbar-brand navbar-left hidden-xs" src="../../static/img/logos/nlp-logo-small.png"
                        alt="" id="imoonlogo">
                    <a class="navbar-brand navbar-left" href="../index.htm">
                        <h3 class="hidden-xs" id="imoontitle" style="font-weight: 600;margin-top: 15px">智能媒体与认知实验室<p
                                style="margin-top: 5px">
                                iMoon: Intelligent
                                Media and Cognition Lab</p>
                        </h3>
                        <h3 class="hidden-sm hidden-md hidden-lg hidden-xl" style="color: white">iMoon-Lab</h3>
                    </a>
                </div>

                <div class="navbar-collapse grove-nav collapse" style="position: relative">
                    <ul class="nav navbar-nav" id="imoonnav">

                        <div style="position:absolute;top:5px;left:10px;border:0px solid rgb(255, 255, 255);">
                            <a href="../../index.htm">
                                <div style="width: 400px;height:65px"></div>
                            </a>
                        </div>
                        <!-- <div id="language">
                            <a id='drump' href="#"><b>中 / </b></a><a id='drump'
                                href="../../../en_tsinghua/resrc/index.htm"><b>En</b></a>
                        </div> -->
                        <li style="margin-top: 1px;">
                            <a href="../../index.htm">主页</a>
                        </li>
                        <li style="margin-top: 1px;">
                            <a href="../../people/index.htm">团队</a>
                        </li>
                        <li style="margin-top: 1px;">
                            <a href="../../resrc/index.htm">研究方向</a>
                        </li>
                        <li style="margin-top: 1px;">
                            <a href="../../pubs/index.htm">论文</a>
                        </li>
                        <li style="margin-top: 1px;">
                            <a href="../../blog/index.htm">新闻</a>
                        </li>
                        <li style="margin-top: 1px;">
                            <a href="../../code/index.htm">源码&数据</a>
                        </li>
                        <li class="dropdown" style="margin-top: 1px;">
                            <a href="#">更多信息</a>
                            <ul class="dropdown-menu">
                                <li><a href="../../more/index.htm">MICCAI19 Tutorial</a></li>
                                <li><a href="#">MICCAI19 挑战赛</a></li>
                            </ul>
                        </li>
                    </ul>
                </div>
            </div>
        </nav>
    </header>

    <div class="container body-content" style="margin-top:90px;">

        <body>
            <h1 align="center" style="font-size:40px;"><b>基于注意力的多模态融合网络在场景语义分割上的应用
            </h1>
            <div class="row">
                <br>
                <p align="center" style="font-size:20px;">
                    李思奇
                </p>
            </div>

            <br>

            <div class="row">
                <div class="col-md-1"></div>
                <div class="col-md-10" style="word-wrap:break-word;hyphens:manual">
                    <!-- <h2><b>Abstract</b></h2> -->
                    <p style="font-size:20px;" wrap="soft">
                        我们提出了一种基于注意力机制的三维卷积网络(AMFNet)用于语义场景补全(SSC)任务，即使用单视角RGB-D图像实现场景完成与语义分割。
                        已有的方法仅使用从RGB-D图像中提取的语义特征实现场景完成，而我们提出的AMFNet可以充分使用2D语义分割信息来同时提升场景完成与语义分割的效果。
                        AMFNet基于2D语义分割实现多模态融合，使用基于残差注意力模块的3D语义场景补全网络提升模型性能。我们在虚拟合成的SUNCG-RGBD数据集
                        和真实采集的NYUv2数据集上进行了验证。实验结果表明，与现有的最佳方法相比，AMFNet在两个数据集上分别实现了2.5%和2.6%的性能提升。
                    </p>
                    <p style="text-align:center;"><img style="width: 100%;" src="research_AMFNet/network.png"
                            alt="xxxx" class="center"></p>
                    <p style="font-size:15px; text-align:left">Figure 1. Architecture of AMFNet. Taking RGB-D images (separated to a RGB and a HHA image) as input, AMFNet predicts
                        voxel occupancy and object labels of the scene simultaneously. It boosts the 3D completion and segmentation from an initial
                        3D semantic feature volume produced by computing the 2D-3D projection of the results of a 2D segmentation network.</p>
                </div>
                <div class="col-md-1"></div>
            </div>

            <br>


            <br>
            
            <div class="row">
                <div class="col-md-1"></div>
                <div class="col-md-10">
                    <h2><b> 方法 </b></h2>
                </div>
                <div class="col-md-1"></div>
            </div>

            <div class="row">
                <div class="col-md-1"></div>
                <div class="col-md-10">

                    <p style="font-size:20px" wrap="hard">
                        The proposed AMFNet, as illustrated in Figure 1, mainly contains three sequential modules: a 2D segmentation network,
                        a 2D-3D projection layer, and a two-branch 3D volume network. This network takes single-view RGB-D images
                        as input and outputs occupancy and semantic labels for all voxels in the scene. The whole network can be trained
                        in an end-to-end manner. We next introduce each module in the sequence of the flow of data processing.
                        The 2D segmentation network extracts 2D geometry features and performs 2D semantic segment-ation from the input RGB-D images.
                        The 2D-3D projection layer projects every feature tensor and semantic label into the 3D volume at the location with the same depth value.
                        The 3D volume network, which takes the output of the 2D-3D projection layer as input, contains two branches: one
                        for 3D guidance information and the other for 3D semantic completion.
                    </p>


                    <p style="text-align:center;"><img style="width: 60%;"  src="research_AMFNet/RAB.png" alt="xxxx" class="center"></p>
                    <p style="font-size:15px; text-align:left;">Figure 2. Illustration of the proposed residual attention block
                        (RAB). RAB has a structure similar to the DDR block but with both channel-wise and spatial-wise
                        attention injected.
                    </p>
                    <br>

                    <p style="font-size:20px" wrap="hard">
                        The 3D-guidance branch is used to provide the guidance information for the branch of 3D semantic
                        completion, which is boosted from an initial 3D semantic volumetric scene where visible voxels have initial
                        semantic labels. The initial 3D semantic volume is encoded by a one-hot encoder to achieve an ROI region (3D
                        bounding box) for a specific category from the initial 3D semantic volume. The one-hot encoding introduces spatial
                        boundary constraints into the network for each category, which improves the prediction of 3D semantic volume. <br><br>

                        The 3D-semantic completion branch, which takes the initial 3D feature volume as input, is mainly used to infer the voxel occupancy
                        of the 3D scene. The RAB block used in the 3D-completion branch is shown in Figure 2.

                    </p>

                </div>
                <div class="col-md-1"></div>
            </div>

            <br>

            <div class="row">
                <div class="col-md-1"></div>
                <div class="col-md-10" style="word-wrap:break-word;hyphens:manual">
                    <h2><b>实验结果</b></h2>

                    <p style="text-align:center;"><img style="width: 100%;margin-top: 30px;" src="research_AMFNet/table.png"
                                                       alt="xxxx" class="center"></p>
                    <br>
                    <p style="font-size:20px;" wrap="soft">
                        Table 1 and Table 2 presents the comparison results of both the scene completion and the semantic
                        scene completion on the NYUv2 dataset and SUNCG-RGBD dataset, respectivly. Compared with previous methods,
                        our model achieves state-of-the-art performance on the task of semantic scene completion and scene completion.
                    </p>

                    <p style="text-align:center;"><img style="width: 100%;" src="research_AMFNet/result.png"
                                                       alt="xxxx" class="center"></p>
                    <p style="font-size:15px; text-align:left">
                        Figure 4. Qualitative results on the NYUv2 dataset.
                        From left to right: RGB image, ground truth of 2D segmentation result, ground truth of SSC task,
                        results generated by SSCNet, SATNet, our approach, our approach with attention block removed,
                        our approach with 3D-guidance branch removed, and our approach with the result of the 2D
                        semantic segmentation module replaced by the ground truth.</p>
                    <br>
                    <p style="font-size:20px;" wrap="soft">
                        The visualization of the qualitative results of the semantic scene completion task generated by the proposed method
                        and two previous methods, SSCNet and SATNet, on a set of representative samples from the NYUv2 dataset is shown in Figure 4.
                        It can be easily seen that our method has achieved better performance than SSCNet and SATNet.
                    </p>

                </div>
                <div class="col-md-1"></div>
            </div>

            <br>

            
            <div class="row">
                <div class="col-md-1"></div>
                <div class="col-md-10">
                    <h2><b> Publications </b></h2>
                </div>
                <div class="col-md-1"></div>
            </div>
            <div class="row">
                <div class="col-md-1"></div>
                <div class="col-md-10">
                    <td>Siqi Li, Changqing Zou, Yipeng Li, Xibin Zhao, Yue Gao. <br><b>Attention Based Multi-modal Fused Network for Semantic Scene Completion.</b><br>AAAI Conference on Artificial Intelligence (AAAI), 2020.</td>
                    <br>
                    <br>
                    <p style="font-size=40px">
                        <a class="btn btn-default" href="#"> <b> Paper &raquo;</b></a>
                        <!-- <a class="btn btn-default" href="#"> <b> Code &raquo;</b></a> -->
                    </p>
                </div>


                <div class="col-md-1"></div>
            </div>




        </body>



        <hr />
        <footer style="background-color: #ffffff">
            <p>&copy; 2020 - iMoonLab 智能媒体与认知实验室 Tsinghua</p>
        </footer>
    </div>
    <script src="static/js/77c25eff67b24c0aa003ead7859d1511.js"></script>

    <script src="static/js/1a59a27fb4484e89ab0510a5871211bd.js"></script>

    <script src="static/js/jquery-ui.min.js"></script>

    <link href="static/css/jquery-ui.min.css" rel="stylesheet" />

    <script src="static/js/shortcut.js"></script>

    <script src="static/js/suggest.js"></script>




</body>

</html>